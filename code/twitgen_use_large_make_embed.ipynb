{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitgen_use_large_make_embed.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyharless/twit_demog/blob/master/twitgen_use_large_make_embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcV34L1AIQ-6",
        "colab_type": "code",
        "outputId": "934a14ad-7840-4d9f-ecb4-95c8a45fe26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "do_mount=True\n",
        "if do_mount:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  !pip install \"tensorflow-gpu==1.13.1\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "路路路路路路路路路路\n",
            "Mounted at /content/gdrive\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     || 345.2MB 69kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.7.1)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     || 368kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     || 3.2MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n",
            "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (41.0.1)\n",
            "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnUyilG-lMEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_save_embeddings = True\n",
        "\n",
        "CORPUS = 'twitgen_big_corpus_201907251843.csv'\n",
        "EMBEDDING_DIM = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-O7uvDmHVSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import our dependencies\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTjRdHaGI2Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basepath = '/content/gdrive/My Drive/twitgen/'\n",
        "model_file_name = 'USELModel_201906161241.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5iFCTZYJ045",
        "colab_type": "code",
        "outputId": "0723f344-4437-44bb-b545-b017f7e57605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "df = pd.read_csv(basepath+CORPUS, index_col=['id','time'], parse_dates=['time'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1703564846</th>\n",
              "      <th>2019-05-21 17:50:48+00:00</th>\n",
              "      <td>I prefer tubs.. but nice try jiggly</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211806644</th>\n",
              "      <th>2019-05-21 17:50:48+00:00</th>\n",
              "      <td>It's the shop. I'd never have paid for 2 year...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971515498411241472</th>\n",
              "      <th>2019-05-21 17:50:48+00:00</th>\n",
              "      <td>Why  cant attend Cannes </td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2430359987</th>\n",
              "      <th>2019-05-21 17:50:49+00:00</th>\n",
              "      <td>Raspberry gin and tonic, nomnom  beautiful ev...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2860188236</th>\n",
              "      <th>2019-05-21 17:50:49+00:00</th>\n",
              "      <td>This is  大Ⅲン筐ю大Ⅲン筐ю大Ⅲン here we g...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                           text   male\n",
              "id                 time                                                                               \n",
              "1703564846         2019-05-21 17:50:48+00:00                I prefer tubs.. but nice try jiggly   True\n",
              "211806644          2019-05-21 17:50:48+00:00   It's the shop. I'd never have paid for 2 year...  False\n",
              "971515498411241472 2019-05-21 17:50:48+00:00                        Why  cant attend Cannes    False\n",
              "2430359987         2019-05-21 17:50:49+00:00  Raspberry gin and tonic, nomnom  beautiful ev...  False\n",
              "2860188236         2019-05-21 17:50:49+00:00    This is  大Ⅲン筐ю大Ⅲン筐ю大Ⅲン here we g...   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uALhDlgHVSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataset\n",
        "texts = df['text'].tolist()\n",
        "texts = [' '.join(t.split()[0:150]) for t in texts]\n",
        "texts = np.array(texts, dtype=object)[:, np.newaxis]\n",
        "labels = df['male'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ3aiS9aILav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize session\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msrIKUwkHVSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)\n",
        "\n",
        "class USEEmbeddingLayer(Layer):\n",
        "    def __init__(self, trainable=True, **kwargs):\n",
        "        self.dimensions = EMBEDDING_DIM\n",
        "        super(USEEmbeddingLayer, self).__init__(**kwargs)\n",
        "        self.trainable=trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.use = hub.Module('https://tfhub.dev/google/universal-sentence-encoder-large/3', trainable=True, #self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "        wts = tf.trainable_variables(scope=\".*{}_module/.*\".format(self.name))\n",
        "        wts = [v for v in wts if not (\"SNLI\" in v.name or \"SHARED_RANK_ANSWER\" in v.name)]\n",
        "        if len(wts)>0:\n",
        "          if self.trainable:\n",
        "            self._trainable_weights += wts\n",
        "          else:\n",
        "            self._non_trainable_weights += wts\n",
        "        else:\n",
        "          print('WARNING: No weights in Embedding Layer')\n",
        "        super(USEEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "   \n",
        "    def call(self, x, mask=None):\n",
        "        result = self.use(tf.squeeze(tf.cast(x, tf.string), axis=1))\n",
        "        return result\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XQHdk5HVSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to build model\n",
        "def build_model(train_embedding=True, optimizer=Adagrad, lr=.003): \n",
        "  input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
        "  embedding = USEEmbeddingLayer(trainable=train_embedding)(input_text)\n",
        "  dense1 = layers.Dense(512, activation='relu')(embedding)\n",
        "\n",
        "  dropout0 = layers.Dropout(.8)(dense1)\n",
        "  pred = layers.Dense(1, activation='sigmoid')(dropout0)\n",
        "\n",
        "  model = Model(inputs=[input_text], outputs=pred)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer(lr), metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06O-5UjUOqlv",
        "colab_type": "code",
        "outputId": "222267c5-4642-427c-f508-9ea01c1d41dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "model = build_model(train_embedding=True)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "table_init = tf.tables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run([init, table_init])\n",
        "K.set_session(sess)\n",
        "\n",
        "lr = 7e-5\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr), metrics=['accuracy'])\n",
        "model.load_weights(basepath+model_file_name)\n",
        "\n",
        "inp = model.input\n",
        "embeddings = model.layers[1].output\n",
        "get_embeddings = K.function([inp],[embeddings])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "use_embedding_layer (USEEmbe (None, 512)               211345728 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 211,608,897\n",
            "Trainable params: 211,608,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlaDAjgLNfMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunk_size = 2**13\n",
        "timestamp = datetime.now().strftime('%Y%m%d%H%M')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_pojthwNfXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_embeddings(df, split, timestamp):\n",
        "\n",
        "  full_len = df.shape[0]\n",
        "  tweet_embeddings = np.empty(shape=[0,EMBEDDING_DIM])\n",
        "\n",
        "  for start in range(0, full_len, chunk_size):\n",
        "    end = min(start+chunk_size, full_len)\n",
        "    embeddings_chunk = get_embeddings([df[['text']].values[start:end]])[0]\n",
        "    tweet_embeddings = np.concatenate([tweet_embeddings, embeddings_chunk])\n",
        "\n",
        "  for i in range(tweet_embeddings.shape[1]):\n",
        "    df['embed'+str(i)] = (tweet_embeddings[:,i]*1e6).astype(int)\n",
        "  \n",
        "  embed_file_name = basepath + 'embed_' + split + '_' + timestamp + '.csv'\n",
        "  df.drop(['text'],axis=1).to_csv(embed_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQA76_JrTS_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_embeddings(df, 'corpus', timestamp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMZAIonXN6Wb",
        "colab_type": "code",
        "outputId": "d1898cf4-d4b3-43e6-ac7a-c433f06a7f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "timestamp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'201907252332'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu5q0qsuaKmK",
        "colab_type": "code",
        "outputId": "b3684914-d6a5-4647-f446-fb1eeaa46283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embed_file_name = basepath + 'embed_' + 'corpus' + '_' + timestamp + '.csv'\n",
        "!ls '$embed_file_name'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/gdrive/My Drive/twitgen/embed_corpus_201907252332.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc1gZx_JdSWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
